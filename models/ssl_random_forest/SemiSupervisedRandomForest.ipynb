{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Добавить страховку на случай, если какое-то дерево обучалось не на всех возможных классах и, как следствие, возвращает предсказание для меньшего количества классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import random\n",
    "from sklearn import tree\n",
    "from scipy.stats import bernoulli\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_binary_pendigits(path_to_data):\n",
    "    df = load_svmlight_file(path_to_data)\n",
    "    features = df[0].todense().view(type=np.ndarray)\n",
    "    target = df[1].astype(np.int)\n",
    "    # classification task is to distinguish between 4 and 9\n",
    "    condition = np.logical_or((target==9),(target==4))\n",
    "    x = features[condition,:]\n",
    "    y = target[condition]\n",
    "    # label is 0, when the image depicts 4, label is 1 otherwise\n",
    "    y[y == 4] = 0\n",
    "    y[y == 9] = 1\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, random_state, train_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=random_state)\n",
    "    x_l_train, x_u_train, y_l_train, y_u_train = train_test_split(x_train, y_train, train_size=train_size, random_state=random_state)\n",
    "    return x_l_train, y_l_train, x_u_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFTree:\n",
    "    def train(self, x, y, random_state):\n",
    "        self.clf = None\n",
    "        self.clf = tree.DecisionTreeClassifier(random_state=random_state, max_features=\"sqrt\", splitter=\"random\") # add random state\n",
    "        self.clf.fit(x, y)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.clf.predict_proba(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def count_oobe(self, x, y):\n",
    "        y_predicted = self.clf.predict(x)\n",
    "        return 1-accuracy_score(y, y_predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, N = 100):\n",
    "        self.N = N\n",
    "        self.trees = []\n",
    "        self.oobe = 0\n",
    "        \n",
    "    def _prepare_train_data(self, x, y):\n",
    "        n_samples = len(y)\n",
    "        steps = 10\n",
    "        st = 0\n",
    "        x_i = []\n",
    "        y_i = []\n",
    "        choices = []\n",
    "        while st < steps:\n",
    "            choices = random.choices(range(0, len(y)), k=n_samples) # indices of samples\n",
    "            y_i = [y[i] for i in choices]\n",
    "            st += 1\n",
    "            if y_i.count(y_i[0]) != len(y_i):\n",
    "                break\n",
    "        if st == steps:\n",
    "            sys.exit(\"We couldn't generate good data for RF\")\n",
    "        x_i = [x[i] for i in choices]\n",
    "        return x_i, y_i, choices\n",
    "    \n",
    "    def _prepare_oob_data(self, x, y, indices):\n",
    "        x_i = [x[i] for i in range(0, len(x)) if i not in indices]\n",
    "        y_i = [y[i] for i in range(0, len(x)) if i not in indices]\n",
    "        return x_i, y_i\n",
    "    \n",
    "    def train(self, x, y, random_state):\n",
    "        random.seed(random_state)\n",
    "        self.trees = []\n",
    "        self.oobe = 0\n",
    "        for i in range(0, self.N):\n",
    "            rfTree = RFTree()\n",
    "            x_i, y_i, idx = self._prepare_train_data(x, y)\n",
    "            #print(\"Train tree with features of size: \", len(x_i[0]))\n",
    "            rfTree.train(x_i, y_i, random_state)\n",
    "            x_oob, y_oob = self._prepare_oob_data(x, y, idx)\n",
    "            self.trees.append(rfTree)\n",
    "            self.oobe += rfTree.count_oobe(x_oob, y_oob)\n",
    "        \n",
    "        self.oobe /= self.N\n",
    "    \n",
    "    def get_oobe(self):\n",
    "        return self.oobe\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        target = self.trees[0].predict_proba(x)\n",
    "        for i in range(1, self.N):\n",
    "            target = np.add(self.trees[i].predict_proba(x), target)        \n",
    "        for i in range(0, len(target)):\n",
    "            target[i] = [x / self.N for x in target[i]]\n",
    "        \n",
    "        return target.tolist()\n",
    "    \n",
    "    def predict_old(self, x):\n",
    "        target = self.predict_proba(x)\n",
    "        res = []\n",
    "        for i in range(0, len(target)):\n",
    "            res.append(target[i].index(max(target[i])))\n",
    "        return res\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y = self.trees[0].predict(x)\n",
    "        for i in range(1, self.N):\n",
    "            y = np.add(self.trees[i].predict(x), y)\n",
    "        res = []\n",
    "        \n",
    "        for i in range(0, len(x)):\n",
    "            if y[i] > self.N/2:\n",
    "                res.append(1)\n",
    "            else:\n",
    "                res.append(0)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiSupervisedRandomForest(RandomForest):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __change_distribution(self, probs, alpha, T):\n",
    "        newprobs = []\n",
    "        for i in range(0, len(probs)):\n",
    "            Z = 0\n",
    "            newprobs_i = []\n",
    "            for p in probs[i]:\n",
    "                #newp = p**(-alpha/T)/np.exp(1) if p > 0 else 0\n",
    "                newp = np.exp(-(alpha*np.log2(p) + T)/T) if p > 0 else 0\n",
    "                newprobs_i.append(newp)\n",
    "                Z += newp\n",
    "            \n",
    "            if np.isinf(Z) or np.any(np.isinf(newprobs_i)):\n",
    "                return [], True\n",
    "            newprobs_i = [p/Z for p in newprobs_i]\n",
    "            newprobs.append(newprobs_i)\n",
    "        return newprobs, False\n",
    "    \n",
    "    def __retrain_random_forest(self, x_l, y_l, x_u, p, random_state):\n",
    "        oobe = 0\n",
    "        np.random.seed(random_state)\n",
    "        for i in range(0, self.N):\n",
    "            y_hat = np.random.binomial(1, p)\n",
    "            x_train = np.concatenate((x_l, x_u))\n",
    "            y_train = np.concatenate((y_l, y_hat))\n",
    "            rfTree = self.trees[i]\n",
    "            for j in range(0, 10):\n",
    "                x_i, y_i, idx = self._prepare_train_data(x_train, y_train)\n",
    "                x_oob, y_oob = self._prepare_oob_data(x_l, y_l, idx)\n",
    "                if len(x_oob) == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    rfTree.train(x_i, y_i, random_state)\n",
    "                    oobe += rfTree.count_oobe(x_oob, y_oob)\n",
    "                    break\n",
    "                if j == 9:\n",
    "                    sys.exit(\"WARNING: We couldnt find good data fot tree#\"+str(i))\n",
    "        oobe /= self.N\n",
    "        return oobe\n",
    "    \n",
    "    def train(self, x_l, y_l, x_u, random_state, T0, alpha, c0):\n",
    "        random.seed(random_state)\n",
    "        steps = 20\n",
    "        #T0 = 0.2 # T_m ~ T0*exp^(-m) - cooling function\n",
    "        #alpha = 0.1\n",
    "        super().train(x_l, y_l, random_state) # train RF with labeled data\n",
    "        Told = T0\n",
    "        m = 0 # set epoch\n",
    "        oobe = 0\n",
    "        while True:\n",
    "            Tnew = Told/c0\n",
    "            m = m + 1\n",
    "            target = self.predict_proba(x_u)\n",
    "            newtarget, is_overflow = self.__change_distribution(target, alpha, Tnew)\n",
    "            if is_overflow:\n",
    "                #print(\"Overflow happened, stopped after \", m, \" steps\")\n",
    "                break\n",
    "            p = [x[1] for x in newtarget]\n",
    "            \n",
    "            oobe = self.__retrain_random_forest(x_l, y_l, x_u, p, random_state)\n",
    "            Told = Tnew\n",
    "            if m >= steps:\n",
    "                break\n",
    "        if oobe > self.oobe:\n",
    "            print(\"[D]Semi-supervised approach was discarded with oobe: \"+str(oobe)+\", oobe for pure RF: \"+str(self.oobe))\n",
    "            random.seed(random_state)\n",
    "            super().train(x_l, y_l, random_state)\n",
    "            \n",
    "        else:\n",
    "            print(\"[A]Semi-supervised approach was accepted with oobe: \"+str(oobe)+\", oobe for pure RF: \"+str(self.oobe))\n",
    "            self.oobe = oobe\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super().predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For dataset 'banknote_authentication':\n",
      "\n",
      "Params:  [0.2, 0.1, 1.1]\n",
      "[D]Semi-supervised approach was discarded with oobe: 0.2878095238095237, oobe for pure RF: 0.18666666666666668\n",
      "[A]Semi-supervised approach was accepted with oobe: 0.16, oobe for pure RF: 0.3441666666666666\n",
      "[D]Semi-supervised approach was discarded with oobe: 0.3449285714285714, oobe for pure RF: 0.25983333333333325\n",
      "[D]Semi-supervised approach was discarded with oobe: 0.17932142857142852, oobe for pure RF: 0.12200000000000001\n",
      "[A]Semi-supervised approach was accepted with oobe: 0.16521428571428573, oobe for pure RF: 0.4820000000000001\n",
      "[D]Semi-supervised approach was discarded with oobe: 0.20238095238095238, oobe for pure RF: 0.20233333333333328\n",
      "[D]Semi-supervised approach was discarded with oobe: 0.2849285714285713, oobe for pure RF: 0.12200000000000001\n",
      "[D]Semi-supervised approach was discarded with oobe: 0.461809523809524, oobe for pure RF: 0.19349999999999995\n",
      "[D]Semi-supervised approach was discarded with oobe: 0.38661111111111096, oobe for pure RF: 0.14650000000000002\n",
      "[A]Semi-supervised approach was accepted with oobe: 0.2056587301587301, oobe for pure RF: 0.2873333333333332\n",
      "Accuracy(with labeled_size = 10): 0.761090909090909\n",
      "\n",
      "--- 135.73463463783264 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def prepare_datasets():\n",
    "    data = dict()\n",
    "    #x, y = read_binary_pendigits(\"datasets/pendigits\")\n",
    "    #data[\"pendigits\"] = ([x, y])\n",
    "    \n",
    "    path = os.path.join('datasets', '01_banknote_authentication.txt')\n",
    "    df = pd.read_csv(path, sep=',', header=None)\n",
    "    x = df.values[:, :-1]\n",
    "    y = df.values[:, -1].astype(int)\n",
    "    data[\"banknote_authentication\"] = ([x, y])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    path = os.path.join('datasets', '08_magic_gamma_telescope.data')\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    #x = df.values[:, :-1]\n",
    "    #y = le.fit_transform(df.values[:, -1])\n",
    "    #data[\"magic_telescope\"] = ([x, y])\n",
    "    \n",
    "    #x = np.load('datasets/MNIST/one_vs_one_data.npy')\n",
    "    #x = x.reshape(x.shape[0], -1)\n",
    "    #y = np.load('datasets/MNIST/one_vs_one_targets.npy')\n",
    "    #data[\"mnist\"] = ([x,y])\n",
    "    return data\n",
    "\n",
    "#main\n",
    "partitions = [10]\n",
    "data = prepare_datasets()\n",
    "\n",
    "params = [[0.2, 0.1, 1.1]] # T0, alpha, c0\n",
    "\n",
    "start_time = time.time()\n",
    "best_params = []\n",
    "best_acc = 0\n",
    "for k,v in data.items():\n",
    "    print(\"\\nFor dataset '\"+k+\"':\\n\")\n",
    "    for p in partitions:\n",
    "        for param in params:\n",
    "            acc = 0\n",
    "            print(\"Params: \", param)\n",
    "            for random_state in range(0, 100, 10):\n",
    "                x_l_train, y_l_train, x_u_train, x_test, y_test = split_data(v[0], v[1], random_state, p)\n",
    "                rf = SemiSupervisedRandomForest()\n",
    "                rf.train(x_l_train, y_l_train, x_u_train, random_state, param[0], param[1], param[2])\n",
    "                y_predicted = rf.predict(x_test)\n",
    "                a = accuracy_score(y_test, y_predicted)\n",
    "                acc += a\n",
    "            acc /= 10\n",
    "            print(\"Accuracy(with labeled_size = \" + str(p) + \"): \" + str(acc)+\"\\n\")\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepare_datasets():\n",
    "    data = dict()\n",
    "    \n",
    "    x, y = read_binary_pendigits(\"datasets/pendigits\")\n",
    "    data[\"pendigits\"] = ([x, y])\n",
    "    \n",
    "    path = os.path.join('datasets', '01_banknote_authentication.txt')\n",
    "    df = pd.read_csv(path, sep=',', header=None)\n",
    "    x = df.values[:, :-1]\n",
    "    y = df.values[:, -1].astype(int)\n",
    "    data[\"banknote_authentication\"] = ([x, y])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    path = os.path.join('datasets', '08_magic_gamma_telescope.data')\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    x= df.values[0:2000, :-1]\n",
    "    y = le.fit_transform(df.values[0:2000, -1])\n",
    "    print(y)\n",
    "    data[\"magic_telescope\"] = ([x, y])\n",
    "    return data\n",
    "\n",
    "#main\n",
    "partitions = [10]\n",
    "data = prepare_datasets()\n",
    "\n",
    "start_time = time.time()\n",
    "for k,v in data.items():\n",
    "    print(\"\\nFor dataset '\"+k+\"':\\n\")\n",
    "    for p in partitions:\n",
    "        acc = 0\n",
    "        for random_state in range(0, 100, 10):\n",
    "            x_l_train, y_l_train, x_u_train, x_test, y_test = split_data(v[0], v[1], random_state, p)\n",
    "            rf = RandomForest()\n",
    "            rf.train(x_l_train, y_l_train, random_state)\n",
    "            y_predicted = rf.predict(x_test)\n",
    "            acc += accuracy_score(y_test, y_predicted)\n",
    "        acc /= 10\n",
    "        print(\"Accuracy(with labeled_size = \" + str(p) + \"): \" + str(acc))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2199\n",
      "\n",
      "For dataset 'pendigits':\n",
      "\n",
      "Accuracy(with labeled_size = 10): 0.8834090909090909\n",
      "Accuracy(with labeled_size = 30): 0.9690909090909091\n",
      "Accuracy(with labeled_size = 50): 0.9752272727272727\n",
      "\n",
      "For dataset 'banknote_authentication':\n",
      "\n",
      "Accuracy(with labeled_size = 10): 0.750909090909091\n",
      "Accuracy(with labeled_size = 30): 0.8789090909090909\n",
      "Accuracy(with labeled_size = 50): 0.9021818181818183\n",
      "\n",
      "For dataset 'magic_telescope':\n",
      "\n",
      "Accuracy(with labeled_size = 10): 0.651472134595163\n",
      "Accuracy(with labeled_size = 30): 0.7172712933753944\n",
      "Accuracy(with labeled_size = 50): 0.7570977917981072\n"
     ]
    }
   ],
   "source": [
    "def prepare_datasets():\n",
    "    data = dict()\n",
    "    \n",
    "    x, y = read_binary_pendigits(\"datasets/pendigits\")\n",
    "    data[\"pendigits\"] = ([x, y])\n",
    "    print(len(y))\n",
    "    path = os.path.join('datasets', '01_banknote_authentication.txt')\n",
    "    df = pd.read_csv(path, sep=',', header=None)\n",
    "    x = df.values[:2000, :-1]\n",
    "    y = df.values[:2000, -1].astype(int)\n",
    "    data[\"banknote_authentication\"] = ([x, y])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    path = os.path.join('datasets', '08_magic_gamma_telescope.data')\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    x= df.values[:, :-1]\n",
    "    y = le.fit_transform(df.values[:, -1])\n",
    "    data[\"magic_telescope\"] = ([x, y])\n",
    "    return data\n",
    "\n",
    "#main\n",
    "partitions = [10, 30, 50]\n",
    "data = prepare_datasets()\n",
    "\n",
    "for k,v in data.items():\n",
    "    print(\"\\nFor dataset '\"+k+\"':\\n\")\n",
    "    for p in partitions:\n",
    "        acc = 0\n",
    "        for random_state in range(0, 100, 10):\n",
    "            x_l_train, y_l_train, x_u_train, x_test, y_test = split_data(v[0], v[1], random_state, p)\n",
    "            rf = RandomForestClassifier(n_estimators=100, random_state=random_state).fit(x_l_train, y_l_train)\n",
    "            y_predicted = rf.predict(x_test)\n",
    "            acc += accuracy_score(y_test, y_predicted)\n",
    "        acc /= 10\n",
    "        print(\"Accuracy(with labeled_size = \" + str(p) + \"): \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
